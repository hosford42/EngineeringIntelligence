[Back to Articles](../README.md#articles)


# What is Language?

It seems superficially obvious to most people that language and intelligence
are closely intertwined. A large vocabulary and the ability to eloquently
communicate are often treated as strong signals of intelligence. Looking at
the broader animal kingdom, the capacity for language seems to automagically 
confer an air of intelligence on other species, such as [gorillas], [African
grey parrots], or [whales]. Conversely, when intelligence is obvious in a
species, such as octopuses, we tend to project upon them an expectation of
language, whether it be in their [body language], their [color changing
patterns], or (facetiously) even their [ink clouds]. And yet we know from
[self-reports] of [autistic people] who were non-verbal and later learn to 
communicate, that language is not required for intelligence to exist. 
Nonetheless, it's clear that people intuitively associate language and 
intelligence. Why, though? What is the actual connection between the two?

## Getting to the Point

Language has a purpose. The primary utility of language is to *communicate*, 
which involves encoding thoughts, ideas, knowledge, queries, or other forms 
of information or data as a stream of sounds or symbols, transmitting or
storing this encoded form through some form of embeddable medium, and then
decoding it again into something approximating its original structure and 
meaning. In this way, one mind can share a fragment of its contents with 
another, provided they possess mutually compatible encoding, transmission,
reception, and decoding schemas. To boil it down: **Language is a [codec] 
for the transfer and storage of meaning outside the mind**.

Assuming our [definition of intelligence] is correct, the information
being conveyed by language is not flat, unstructured data, but is rather
a [serialization] of some component or aspect of the internal 
representative model of the environment held by a mind. When we 
communicate, the speaker gathers up some tiny subset of the vast, 
interconnected knowledge or beliefs they hold in their mind, convert this
into an utterance that encodes its contents and structure, and pass 
it to the listener. The listener then decodes the contents and structure
from that utterance and attempts to incorporate it into their own mental
model.

## Impedance Mismatch

Now here's the rub: No two people share the same mental model. There is
inevitably a vast array of subtle differences in each person's internal
model of reality, thanks to the uniqueness of each person's developmental
experiences. So what happens when there are local differences in two 
people's mental models in the vicinity of the fragment of meaning that
is represented by a particular act of communication? Somehow, language
also has to address the problem of [impedance mismatch] between two
minds -- when one person's beliefs about, or even fundamental 
conceptualizations of, reality differ from another's.

Thankfully, though there can be vast and significant differences between
people's perspectives, our developmental wiring patterns and common human 
experiences of the world we live in also lead to significant commonalities.
Human language has evolved to take advantage of these commonalities to offer 
a robust encoding of human-originated meaning in such a way that, even when
two people have vastly different understandings of the world, they can,
with sufficient determination, usually understand each other's intent.

Language achieves this by using words to represent broad conceptual 
categories, which are then linked together through relationships signified 
by the form or arrangement of those words. When a concept or relationship
conveyed by an utterance is not directly matched in the listener's mind,
it is generally possible to infer the appropriate match by matching the
other concepts and relationships in the utterance and then searching the
neighborhood of those matched concepts to find an appropriate match for
the questionable content.

For example, suppose someone refers to "the biscuit you just ate", to 
someone who uses the American name for it, "cookie". The American, 
presumably unfamiliar with British usage, would probably think 
at first of something the speaker would call a "scone" instead. But
right away, the American will recognize that this does not match 
contextually with what they believe transpired, and will either 
accept that the speaker actually meant what they think of as a "cookie", 
or else question the speaker on their unexpected wording. This is all
possible because of the surrounding words, "the ___ you just ate,"
which provide a relational context in the listener's mental model
that vastly narrows down the potential conceptual binding points for 
the word "biscuit". (I hope I got the British usage right. I confess, 
I'm a mere American.)

**TODO: Embed a diagram here showing the parse tree of the language
fragment, the local vicinity of the binding point in the listener's
mental model (represented as a knowledge graph), and the contextual
alignment between the two that allows the mismatch to be precisely
identified.**

## Inter-Species Communication

The theory of language presented here has significant implications
for inter-species communication, whether it be between ourselves
and other intelligent species we share this planet with, or with
extra-terrestrials we might someday encounter. Our communication
with each other is significantly eased by the fact that we have
very similar mental structures and experiences, and yet even a
small difference in our neural wiring diagrams can result in what
is called, in the autistic community, the [double empathy problem].
With other species, this difference in the conceptualization,
structure, and linguistic encoding of our mental models may 
easily be so vast that it becomes impossible to ever understand 
each other on a level approaching what we have among ourselves, 
even if the two species are of similar levels of mental
complexity. This is not to say that inter-species communication
is not worth the effort, but that we should approach the
problem *minus* the expectation of someday creating a magical
Star Trek-style translator. 

## Human-Machine Communication

Our machines are another matter. Because they are engineered,
we can potentially tune their mental models to be sufficiently 
compatible with our own to make effective communication feasible.
We can build machines that conceptualize the world in terms of
things (nouns), events (verbs), properties (adjectives/adverbs), 
relationships (prepositions), and other fundamental or near-fundamental 
semantic elements that at least approximate our own. To accomplish
this, we must take a close look at the semantic elements that
comprise our natural languages.

Because the purpose of language is to communicate portions of our 
mental models, the elements and structure of our languages should 
offer us strong clues as to how human beings represent our world in 
our mental models. These clues may not tell us *everything* we need 
to know, as it's possible to imagine things we *can't* communicate 
effectively with language (qualia being a glaring example), but they 
will still provide an enormous level of insight into how our minds 
work.




[gorillas]: 
https://en.wikipedia.org/wiki/Great_ape_language

[African grey parrots]: 
https://en.wikipedia.org/wiki/Alex_(parrot)

[whales]: 
https://www.nationalgeographic.com/animals/article/scientists-plan-to-use-ai-to-try-to-decode-the-language-of-whales

[body language]:
https://www.newscientist.com/article/2075556-octopuses-resolve-conflicts-with-many-armed-body-language/

[color changing patterns]:
https://qz.com/908695/squid-speak-a-unique-undeciphered-language-using-their-skin/

[ink clouds]: 
http://www.northofreality.com/tales/2016/12/27/octopus-language

[self-reports]:
https://lithub.com/a-first-hand-account-of-severe-autism/

[autistic people]:
https://www.verywellmind.com/should-you-say-person-with-autism-or-autistic-person-5235429#toc-identity-first-vs-person-first-language-and-autism

[codec]:
https://en.wikipedia.org/wiki/Codec

[definition of intelligence]:
AnInformalDefinitionOfIntelligence.md

[serialization]:
https://en.wikipedia.org/wiki/Serialization

[impedance mismatch]:
https://en.wikipedia.org/wiki/Object%E2%80%93relational_impedance_mismatch

[double empathy problem]:
https://www.spectrumnews.org/news/double-empathy-explained/
